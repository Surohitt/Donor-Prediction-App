{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "Below is a notebook where I tested some functions to input into the backend of the web app in order to pre-process user inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Importing basic libraries for data analytics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries for visualisations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from scipy.stats import norm\n",
    "import scipy\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline\n",
    "\n",
    "# Import supplementary visualization code visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "# Used for tracking model training and testing time\n",
    "from time import time\n",
    "\n",
    "# Importing 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import sklearn.preprocessing.StandardScaler for feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import two metrics from sklearn - fbeta_score and accuracy_score\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "# Importing Precision function\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "# Importing the three supervised learning models from sklearn\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "# Importing pickle to help with model saving and loading\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs():\n",
    "\n",
    "    input_vals = 25,'Federal-gov','Bachelors',10,'Married-spouse-absent','Sales','Husband','Black','Male',40000,1200,50,'Canada'\n",
    "\n",
    "    return input_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # List of column names to pass to the read_csv function\n",
    "    col_names = ['age','workclass','fnlwgt','education','education_years','marital_status','occupation','realtionship','race',\n",
    "         'sex','capital_gain','capital_loss','hours_worked_per_week','native_country','income']\n",
    "\n",
    "    # Loading in our training data\n",
    "    data = pd.read_csv('adultdata', names=col_names)\n",
    "\n",
    "    # Loading in the testing data\n",
    "    data_test = pd.read_csv('adulttest', names=col_names, skiprows=1)\n",
    "\n",
    "    # Merging our dataframes\n",
    "    merged_data = pd.concat([data,data_test],ignore_index = True)\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_scaler_header(data):\n",
    "    '''\n",
    "    INPUT:\n",
    "    data - Pandas Dataframe of our raw data\n",
    "\n",
    "    OUTPUT:\n",
    "    fitted_scaler - return the scaler object \n",
    "    features_headers - list of pandas headers for cleaned dataframe\n",
    "\n",
    "    Description:\n",
    "    returns a scalar object and headers used to train data to use on the inputs of the web app\n",
    "    '''\n",
    "    # Removing the fnlwgt column in one line\n",
    "    data.drop(['fnlwgt'], axis = 1, inplace = True)\n",
    "\n",
    "    # indexing the ' ?' rows\n",
    "    q_indx = list(np.nonzero(data.isin([' ?']).sum(axis=1)>0)[0])\n",
    "    # Storing the drop\n",
    "    data.drop(axis=0, index = q_indx, inplace =True)\n",
    "\n",
    "    # list of all continuous features\n",
    "    cont_feat = list(data.dtypes[data.dtypes == 'int64'].index)\n",
    "\n",
    "    # creating a list of of column names\n",
    "    skewed_cols = ['capital_gain','capital_loss']\n",
    "\n",
    "    # Log transforming the skewed features\n",
    "    features_log_transformed = pd.DataFrame(data = data)\n",
    "    features_log_transformed[skewed_cols] = data[skewed_cols].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "\n",
    "    # Initialize a scaler, then apply it to the features with a default of 0 -> 1\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Copying the dataframe over to a new one\n",
    "    features_log_minmax_transform = features_log_transformed.copy()\n",
    "    \n",
    "    # Transforming our new dataframes continuous features\n",
    "    fitted_scaler = scaler.fit(features_log_transformed[cont_feat])\n",
    "    features_log_minmax_transform[cont_feat] = fitted_scaler.transform(features_log_transformed[cont_feat])\n",
    "    \n",
    "    \n",
    "    # Split the data into features and target label\n",
    "    features_log_minmax_transform.drop('income', axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # One-hot encode the 'features_log_minmax_transform' data using pandas.get_dummies()\n",
    "    features_final = pd.get_dummies(features_log_minmax_transform)\n",
    "    features_final.columns = features_final.columns.str.replace(' ', '')\n",
    "    features_headers = list(features_final.columns)\n",
    "    \n",
    "\n",
    "    return fitted_scaler, features_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_inputs(data, fitted_scaler):\n",
    "    '''\n",
    "    INPUT:\n",
    "    data - Pandas Dataframe of our raw inputs\n",
    "    fitted_scaler - scaler object used in our clean_data function\n",
    "\n",
    "    OUTPUT:\n",
    "    features_final - Pandas dataframe of our processed input features\n",
    "\n",
    "    Description:\n",
    "    Cleans the data in a pipeline process\n",
    "    '''\n",
    "\n",
    "    cont_feat = ['age',\n",
    "     'education_years',\n",
    "     'capital_gain',\n",
    "     'capital_loss',\n",
    "     'hours_worked_per_week']\n",
    "\n",
    "    for feat in cont_feat:\n",
    "        data[feat] = data[feat].astype(str).astype(int)\n",
    "\n",
    "    # creating a list of of column names\n",
    "    skewed_cols = ['capital_gain','capital_loss']\n",
    "\n",
    "    # Log transforming the skewed features\n",
    "    features_log_transformed = pd.DataFrame(data = data)\n",
    "    features_log_transformed[skewed_cols] = data[skewed_cols].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "    # Copying the dataframe over to a new one\n",
    "    features_log_minmax_transform = features_log_transformed.copy()\n",
    "    features_log_minmax_transform[cont_feat] = fitted_scaler.transform(features_log_transformed[cont_feat])\n",
    "\n",
    "    # One-hot encode the 'features_log_minmax_transform' data using pandas.get_dummies()\n",
    "    features_final = pd.get_dummies(features_log_minmax_transform)\n",
    "    features_final.columns = features_final.columns.str.replace(' ', '')\n",
    "\n",
    "    return features_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_dataframe_for_input(clean_inputs, column_headers):\n",
    "    '''\n",
    "    INPUT:\n",
    "    clean_inputs - pandas dataframe of our cleaned inputs\n",
    "    column_headers - column headers of our features dataframe we used for training our model \n",
    "    \n",
    "    OUTPUT:\n",
    "    input_df - Pandas dataframe of our processed input features with the correct column headers\n",
    "    \n",
    "    Description:\n",
    "    Cleans the data in a pipeline process\n",
    "    '''\n",
    "    \n",
    "    # Empty Dataframe with features headers\n",
    "    input_df = pd.DataFrame(index=[0], columns = column_headers)\n",
    "    # Passing values to our empty dataframe\n",
    "    for col in list(clean_inputs.columns):\n",
    "        input_df[col] = clean_inputs[col][0]\n",
    "    # Filling the Na's with 0\n",
    "    input_df.fillna(0, inplace=True)\n",
    "    \n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning merged data\n",
    "merged_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:51: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Getting the scaler object and cleaned feature headers\n",
    "fitted_scaler, features_headers = return_scaler_header(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = get_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our inputs in a dataframe format\n",
    "df_inputs = pd.DataFrame(index = [0], columns = list(merged_data.columns[0:13]))\n",
    "df_inputs.loc[0,:] = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling our dataframe\n",
    "scaled_inputs = clean_inputs(df_inputs, fitted_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education_years</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_worked_per_week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>education_Bachelors</th>\n",
       "      <th>marital_status_Married-spouse-absent</th>\n",
       "      <th>occupation_Sales</th>\n",
       "      <th>realtionship_Husband</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>native_country_Canada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.920414</td>\n",
       "      <td>0.846217</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  education_years  capital_gain  capital_loss  \\\n",
       "0  0.109589              0.6      0.920414      0.846217   \n",
       "\n",
       "   hours_worked_per_week  workclass_Federal-gov  education_Bachelors  \\\n",
       "0                    0.5                      1                    1   \n",
       "\n",
       "   marital_status_Married-spouse-absent  occupation_Sales  \\\n",
       "0                                     1                 1   \n",
       "\n",
       "   realtionship_Husband  race_Black  sex_Male  native_country_Canada  \n",
       "0                     1           1         1                      1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching the headers\n",
    "clean_input_df = matching_dataframe_for_input(scaled_inputs, features_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education_years</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_worked_per_week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native_country_Portugal</th>\n",
       "      <th>native_country_Puerto-Rico</th>\n",
       "      <th>native_country_Scotland</th>\n",
       "      <th>native_country_South</th>\n",
       "      <th>native_country_Taiwan</th>\n",
       "      <th>native_country_Thailand</th>\n",
       "      <th>native_country_Trinadad&amp;Tobago</th>\n",
       "      <th>native_country_United-States</th>\n",
       "      <th>native_country_Vietnam</th>\n",
       "      <th>native_country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.920414</td>\n",
       "      <td>0.846217</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  education_years  capital_gain  capital_loss  \\\n",
       "0  0.109589              0.6      0.920414      0.846217   \n",
       "\n",
       "   hours_worked_per_week  workclass_Federal-gov  workclass_Local-gov  \\\n",
       "0                    0.5                      1                    0   \n",
       "\n",
       "   workclass_Private  workclass_Self-emp-inc  workclass_Self-emp-not-inc  ...  \\\n",
       "0                  0                       0                           0  ...   \n",
       "\n",
       "   native_country_Portugal  native_country_Puerto-Rico  \\\n",
       "0                        0                           0   \n",
       "\n",
       "   native_country_Scotland  native_country_South  native_country_Taiwan  \\\n",
       "0                        0                     0                      0   \n",
       "\n",
       "   native_country_Thailand  native_country_Trinadad&Tobago  \\\n",
       "0                        0                               0   \n",
       "\n",
       "   native_country_United-States  native_country_Vietnam  \\\n",
       "0                             0                       0   \n",
       "\n",
       "   native_country_Yugoslavia  \n",
       "0                          0  \n",
       "\n",
       "[1 rows x 103 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the new data frame\n",
    "clean_input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the highest accuracy model\n",
    "filename = 'model.pkl'\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(clean_input_df)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
